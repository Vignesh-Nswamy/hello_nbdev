---

title: Crawler


keywords: fastai
sidebar: home_sidebar

summary: "Defines methods to crawl all web pages in a specific domain, extract contents from them and store them in a DataFrame "
description: "Defines methods to crawl all web pages in a specific domain, extract contents from them and store them in a DataFrame "
nb_path: "nbs/03_crawler.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/03_crawler.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="link_filter" class="doc_header"><code>link_filter</code><a href="https://github.com/Vignesh-Nswamy/search_engine/tree/master/search_engine/crawler.py#L16" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>link_filter</code>(<strong><code>link</code></strong>, <strong><code>domain</code></strong>, <strong><code>base_url</code></strong>)</p>
</blockquote>
<p>Filters out links if they...</p>
<ol>
<li><p>Are not from specified domain</p>
</li>
<li><p>Contain extensions - pdf|jpg|jpeg|doc|docx|ppt|pptx|png|txt|exe|ps|psb</p>
</li>
<li><p>Contain an <code>@</code></p>
</li>
<li><p>Have already been visited</p>
</li>
</ol>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="link_modifier" class="doc_header"><code>link_modifier</code><a href="https://github.com/Vignesh-Nswamy/search_engine/tree/master/search_engine/crawler.py#L31" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>link_modifier</code>(<strong><code>url</code></strong>, <strong><code>base_url</code></strong>)</p>
</blockquote>
<p>Converts <code>relative</code> urls to absolute ones.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="crawl" class="doc_header"><code>crawl</code><a href="https://github.com/Vignesh-Nswamy/search_engine/tree/master/search_engine/crawler.py#L44" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>crawl</code>(<strong><code>domain</code></strong>=<em><code>'uic.edu'</code></em>, <strong><code>url</code></strong>=<em><code>'https://cs.uic.edu'</code></em>, <strong><code>num_pages</code></strong>=<em><code>5</code></em>)</p>
</blockquote>
<p>Starts crawling the specified url and linked urls in a breadth-first fashion,
extracts content and puts them in a DataFrame that will be returned</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

